---
title: "In-Class Exercise 8 - Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method"
format:
  html:
    code-fold: true
    code-summary: "Show the code"

execute: 
  eval: true
  echo: true
  warning: false
  freeze: true

date: "`r Sys.Date()`"
---

# 1.0 installing packages 

```{r}
pacman::p_load(olsrr, corrplot, ggpubr, sf, spdep, GWmodel, tmap, tidyverse, gtsummary, ggstatsplot)

```

ggstatsplot - for visualizing the results of statistical tests. We will use it to compare with other models. 

# 2.0 Data preparation

## 2.1 Geospatial Data 

```{r}
mpsz = st_read(dsn = "data/geospatial", layer = "MP14_SUBZONE_WEB_PL")
```

```{r}
mpsz_svy21 <- st_transform(mpsz, 3414)
```

```{r}
condo_resale = read_csv("data/aspatial/Condo_resale_2015.csv")
```


```{r}
condo_resale.sf <- st_as_sf(condo_resale,
                            coords = c("LONGITUDE", "LATITUDE"),
                            crs=4326) %>%
  st_transform(crs=3414)
```

::: call-out note always read the long then lat. column names in c() should follow the same name as the data. 

# 3.0 hedonic pricing modelling in R (HANDS ON example)

In this section, you will learn how to building hedonic pricing models for condominium resale units using lm() of R base.

## 3.1 Simple Linear Regression Method

```{r}
condo.slr <- lm(formula=SELLING_PRICE ~ AREA_SQM, data = condo_resale.sf)
```


lm() returns an object of class “lm” or for multiple responses of class c(“mlm”, “lm”).

The functions summary() and anova() can be used to obtain and print a summary and analysis of variance table of the results. The generic accessor functions coefficients, effects, fitted.values and residuals extract various useful features of the value returned by lm.

```{r}
summary(condo.slr)
```
The output report reveals that the SELLING_PRICE can be explained by using the formula:

      *y = -258121.1 + 14719x1*
The R-squared of 0.4518 reveals that the simple regression model built is able to explain about 45% of the resale prices.

Since p-value is much smaller than 0.0001, we will reject the null hypothesis that mean is a good estimator of SELLING_PRICE. This will allow us to infer that simple linear regression model above is a good estimator of SELLING_PRICE.

The Coefficients: section of the report reveals that the p-values of both the estimates of the Intercept and ARA_SQM are smaller than 0.001. In view of this, the null hypothesis of the B0 and B1 are equal to 0 will be rejected. As a results, we will be able to infer that the B0 and B1 are good parameter estimates.

```{r}
ggplot(data=condo_resale.sf,  
       aes(x=`AREA_SQM`, y=`SELLING_PRICE`)) +
  geom_point() +
  geom_smooth(method = lm)
```
## 3.2 Multiple Linear Regression Method

```{r}
corrplot(cor(condo_resale[, 5:23]), diag = FALSE, order = "AOE",
         tl.pos = "td", tl.cex = 0.5, method = "number", type = "upper")
```


Matrix reorder is very important for mining the hiden structure and patter in the matrix. There are four methods in corrplot (parameter order), named “AOE”, “FPC”, “hclust”, “alphabet”. In the code chunk above, AOE order is used. It orders the variables by using the angular order of the eigenvectors method suggested by Michael Friendly.

From the scatterplot matrix, it is clear that Freehold is highly correlated to LEASE_99YEAR. In view of this, it is wiser to only include either one of them in the subsequent model building. As a result, LEASE_99YEAR is excluded in the subsequent model building.

## 3.3 Building a hedonic pricing model using multiple linear regression method

```{r}
condo.mlr <- lm(formula = SELLING_PRICE ~ AREA_SQM + AGE    + 
                  PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE +
                  PROX_URA_GROWTH_AREA + PROX_HAWKER_MARKET + PROX_KINDERGARTEN + 
                  PROX_MRT  + PROX_PARK + PROX_PRIMARY_SCH + 
                  PROX_TOP_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_SUPERMARKET + 
                  PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, 
                data=condo_resale.sf)
summary(condo.mlr)
```

::: call-out note selling_price is the dependent variable. everything else with + sign is independent variable.

## 3.4 Preparing Publication Quality Table: olsrr method

```{r}
condo.mlr1 <- lm(formula = SELLING_PRICE ~ AREA_SQM + AGE + 
                   PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE +
                   PROX_URA_GROWTH_AREA + PROX_MRT  + PROX_PARK + 
                   PROX_PRIMARY_SCH + PROX_SHOPPING_MALL    + PROX_BUS_STOP + 
                   NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD,
                 data=condo_resale.sf)
ols_regress(condo.mlr1)
```
## 3.5 Preparing Publication Quality Table: gtsummary method

```{r}
tbl_regression(condo.mlr1, intercept = TRUE)
```

With gtsummary package, model statistics can be included in the report by either appending them to the report table by using add_glance_table() or adding as a table source note by using add_glance_source_note() as shown in the code chunk below.

```{r}
tbl_regression(condo.mlr1, 
               intercept = TRUE) %>% 
  add_glance_source_note(
    label = list(sigma ~ "\U03C3"),
    include = c(r.squared, adj.r.squared, 
                AIC, statistic,
                p.value, sigma))
```

### 3.5.1 Check for multi colinearity 

In this section, we would like to introduce you a fantastic R package specially programmed for performing OLS regression. It is called olsrr. It provides a collection of very useful methods for building better multiple linear regression models:

comprehensive regression output
residual diagnostics
measures of influence
heteroskedasticity tests
collinearity diagnostics
model fit assessment
variable contribution assessment
variable selection procedures

In the code chunk below, the ols_vif_tol() of olsrr package is used to test if there are sign of multicollinearity.

```{r}
ols_vif_tol(condo.mlr1)
```

### 3.5.2 Test for Non-Linearity

In multiple linear regression, it is important for us to test the assumption that linearity and additivity of the relationship between dependent and independent variables.

In the code chunk below, the ols_plot_resid_fit() of olsrr package is used to perform linearity assumption test.

```{r}
ols_plot_resid_fit(condo.mlr1)
```



### 3.5.3 Test for Normality Assumption

Lastly, the code chunk below uses ols_plot_resid_hist() of olsrr package to perform normality assumption test.

```{r}
ols_plot_resid_hist(condo.mlr1)
```

The figure reveals that the residual of the multiple linear regression model (i.e. condo.mlr1) is resemble normal distribution.

If you prefer formal statistical test methods, the ols_test_normality() of olsrr package can be used as shown in the code chun below.

```{r}
ols_test_normality(condo.mlr1)
```

The summary table above reveals that the p-values of the four tests are way smaller than the alpha value of 0.05. Hence we will reject the null hypothesis and infer that there is statistical evidence that the residual are not normally distributed.

### 3.5.4 Testing for Spatial Autocorrelation

The hedonic model we try to build are using geographically referenced attributes, hence it is also important for us to visual the residual of the hedonic pricing model.

In order to perform spatial autocorrelation test, we need to convert condo_resale.sf from sf data frame into a SpatialPointsDataFrame.

First, we will export the residual of the hedonic pricing model and save it as a data frame.

```{r}
mlr.output <- as.data.frame(condo.mlr1$residuals)

```

```{r}
condo_resale.res.sf <- cbind(condo_resale.sf, 
                        condo.mlr1$residuals) %>%
rename(`MLR_RES` = `condo.mlr1.residuals`)
```

```{r}
condo_resale.sp <- as_Spatial(condo_resale.res.sf)
condo_resale.sp
```

```{r}
tmap_mode("view")
```


```{r}
tm_shape(mpsz_svy21)+
  tmap_options(check.and.fix = TRUE) +
  tm_polygons(alpha = 0.4) +
tm_shape(condo_resale.res.sf) +  
  tm_dots(col = "MLR_RES",
          alpha = 0.6,
          style="quantile") +
  tm_view(set.zoom.limits = c(11,14))
```


```{r}
tmap_mode("plot")
```

The figure above reveal that there is sign of spatial autocorrelation.

To proof that our observation is indeed true, the Moran’s I test will be performed

First, we will compute the distance-based weight matrix by using dnearneigh() function of spdep.

```{r}
nb <- dnearneigh(coordinates(condo_resale.sp), 0, 1500, longlat = FALSE)
summary(nb)
```

Next, nb2listw() of spdep packge will be used to convert the output neighbours lists (i.e. nb) into a spatial weights.

```{r}
nb_lw <- nb2listw(nb, style = 'W')
summary(nb_lw)
```
Next, lm.morantest() of spdep package will be used to perform Moran’s I test for residual spatial autocorrelation

```{r}
lm.morantest(condo.mlr1, nb_lw)

```

# 4 MODELLING BUT USING GGSTATPLOT 

ggplot2 is a data visualization package that is based on the grammar of graphics. It is a powerful tool for visualizing the results of statistical tests. We will use it to compare with other models.


```{r}
#| fig-width: 12
#| fig-height: 10

ggcorrmat(condo_resale[,5:23])
```
corrplot can set the different methods in the function. However, ggcorrmat can only use the default method. However, ggcorrmat can be used to visualize the correlation matrix of the data. Statistical information can be immediately displayed on the plot. 

```{r}

```


```{r}
#| fig-height: 12
mlr.p <- ggcoefstats(condo.mlr1, sort = "ascending")
mlr.p
```
::: call-out note this is used in comparison to section 3.5. It uses ggcoefstats to visualize the results of the model. it plots with the regression coefficients' point estimates as dots with confidence intervals as line. We can alter the parameters to aid our visuals. 



